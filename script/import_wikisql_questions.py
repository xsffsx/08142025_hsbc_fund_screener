#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
WikiSQLé—®é¢˜æ•°æ®å¯¼å…¥è„šæœ¬
ä¸“é—¨å¯¼å…¥dev.jsonlä¸­çš„é—®é¢˜å’ŒSQLæŸ¥è¯¢æ•°æ®
ä½œè€…: Augment Agent
æ—¥æœŸ: 2025-02-04
"""

import json
import mysql.connector
from mysql.connector import Error
from pathlib import Path
from tqdm import tqdm
import logging
import sys
from typing import Dict, Optional

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class WikiSQLQuestionsImporter:
    def __init__(self, mysql_config: Dict, wikisql_data_path: str):
        self.mysql_config = mysql_config
        self.wikisql_path = Path(wikisql_data_path)
        self.mysql_conn = None
        
    def connect_mysql(self) -> bool:
        """è¿æ¥MySQLæ•°æ®åº“"""
        try:
            self.mysql_conn = mysql.connector.connect(**self.mysql_config)
            logger.info("âœ… MySQLè¿æ¥æˆåŠŸ")
            return True
        except Error as e:
            logger.error(f"âŒ MySQLè¿æ¥å¤±è´¥: {e}")
            return False
    
    def get_table_meta_id(self, table_id: str) -> Optional[int]:
        """è·å–è¡¨çš„meta_id"""
        if not self.mysql_conn:
            return None
        
        try:
            cursor = self.mysql_conn.cursor()
            cursor.execute(
                "SELECT id FROM wikisql_tables_meta WHERE original_table_id = %s",
                (table_id,)
            )
            result = cursor.fetchone()
            cursor.close()
            
            return result[0] if result else None
            
        except Error as e:
            logger.error(f"âŒ è·å–è¡¨meta_idå¤±è´¥: {e}")
            return None
    
    def import_questions(self, data_source: str) -> bool:
        """å¯¼å…¥é—®é¢˜æ•°æ®"""
        questions_file = self.wikisql_path / f"{data_source}.jsonl"
        
        if not questions_file.exists():
            logger.error(f"é—®é¢˜æ–‡ä»¶ä¸å­˜åœ¨: {questions_file}")
            return False
        
        logger.info(f"ğŸ“¥ å¼€å§‹å¯¼å…¥ {data_source} é—®é¢˜æ•°æ®...")
        
        try:
            cursor = self.mysql_conn.cursor()
            
            # ç»Ÿè®¡ä¿¡æ¯
            total_questions = 0
            success_count = 0
            error_count = 0
            missing_table_count = 0
            
            with open(questions_file, 'r', encoding='utf-8') as f:
                # å…ˆè®¡ç®—æ€»è¡Œæ•°
                lines = f.readlines()
                total_lines = len(lines)
                
                logger.info(f"å‘ç° {total_lines} ä¸ªé—®é¢˜")
                
                # é‡æ–°è¯»å–æ–‡ä»¶è¿›è¡Œå¤„ç†
                f.seek(0)
                
                for line_num, line in enumerate(tqdm(lines, desc=f"å¯¼å…¥{data_source}é—®é¢˜"), 1):
                    try:
                        question_data = json.loads(line.strip())
                        total_questions += 1
                        
                        table_id = question_data['table_id']
                        
                        # æŸ¥æ‰¾å¯¹åº”çš„è¡¨å…ƒæ•°æ®ID
                        table_meta_id = self.get_table_meta_id(table_id)
                        
                        if not table_meta_id:
                            missing_table_count += 1
                            if missing_table_count <= 10:  # åªæ˜¾ç¤ºå‰10ä¸ªç¼ºå¤±çš„è¡¨
                                logger.warning(f"æœªæ‰¾åˆ°è¡¨ {table_id} çš„å…ƒæ•°æ®")
                            continue
                        
                        # æ’å…¥é—®é¢˜
                        insert_question = """
                        INSERT INTO wikisql_questions 
                        (table_meta_id, question, sql_select_col, sql_agg_func, 
                         sql_conditions, data_source)
                        VALUES (%s, %s, %s, %s, %s, %s)
                        """
                        
                        sql_info = question_data.get('sql', {})
                        
                        cursor.execute(insert_question, (
                            table_meta_id,
                            question_data['question'],
                            sql_info.get('sel'),
                            sql_info.get('agg'),
                            json.dumps(sql_info.get('conds', [])),
                            data_source
                        ))
                        
                        success_count += 1
                        
                        # æ¯1000æ¡æäº¤ä¸€æ¬¡
                        if success_count % 1000 == 0:
                            self.mysql_conn.commit()
                            logger.info(f"å·²å¯¼å…¥ {success_count} ä¸ªé—®é¢˜...")
                        
                    except json.JSONDecodeError as e:
                        logger.warning(f"è·³è¿‡æ— æ•ˆJSONè¡Œ {line_num}: {e}")
                        error_count += 1
                        continue
                    except Exception as e:
                        logger.error(f"å¤„ç†é—®é¢˜ {line_num} æ—¶å‘ç”Ÿé”™è¯¯: {e}")
                        error_count += 1
                        continue
            
            # æœ€ç»ˆæäº¤
            self.mysql_conn.commit()
            cursor.close()
            
            logger.info(f"ğŸ‰ {data_source} é—®é¢˜æ•°æ®å¯¼å…¥å®Œæˆ!")
            logger.info(f"   æ€»é—®é¢˜æ•°: {total_questions}")
            logger.info(f"   æˆåŠŸå¯¼å…¥: {success_count}")
            logger.info(f"   é”™è¯¯æ•°é‡: {error_count}")
            logger.info(f"   ç¼ºå¤±è¡¨æ•°: {missing_table_count}")
            
            return True
            
        except Exception as e:
            logger.error(f"âŒ å¯¼å…¥é—®é¢˜æ•°æ®å¤±è´¥: {e}")
            return False
    
    def get_import_statistics(self) -> Dict:
        """è·å–å¯¼å…¥ç»Ÿè®¡ä¿¡æ¯"""
        if not self.mysql_conn:
            return {}
        
        try:
            cursor = self.mysql_conn.cursor(dictionary=True)
            
            stats = {}
            
            # é—®é¢˜ç»Ÿè®¡
            cursor.execute("""
                SELECT data_source, COUNT(*) as question_count 
                FROM wikisql_questions 
                GROUP BY data_source
            """)
            stats['questions_by_source'] = {row['data_source']: row['question_count'] 
                                          for row in cursor.fetchall()}
            
            # æ€»ä½“ç»Ÿè®¡
            cursor.execute("SELECT COUNT(*) as total_questions FROM wikisql_questions")
            stats['total_questions'] = cursor.fetchone()['total_questions']
            
            # è¡¨è¦†ç›–ç‡
            cursor.execute("""
                SELECT 
                    COUNT(DISTINCT wq.table_meta_id) as tables_with_questions,
                    (SELECT COUNT(*) FROM wikisql_tables_meta) as total_tables
                FROM wikisql_questions wq
            """)
            result = cursor.fetchone()
            stats['tables_with_questions'] = result['tables_with_questions']
            stats['total_tables'] = result['total_tables']
            stats['coverage_percentage'] = round(
                (result['tables_with_questions'] / result['total_tables']) * 100, 2
            ) if result['total_tables'] > 0 else 0
            
            cursor.close()
            return stats
            
        except Exception as e:
            logger.error(f"âŒ è·å–ç»Ÿè®¡ä¿¡æ¯å¤±è´¥: {e}")
            return {}
    
    def close_connection(self):
        """å…³é—­æ•°æ®åº“è¿æ¥"""
        if self.mysql_conn:
            self.mysql_conn.close()
            logger.info("ğŸ”Œ æ•°æ®åº“è¿æ¥å·²å…³é—­")


def main():
    """ä¸»å‡½æ•°"""
    # MySQLé…ç½®
    mysql_config = {
        'host': 'localhost',
        'port': 3306,
        'database': 'nl2sql',
        'user': 'nl2sql_user',
        'password': 'nl2sql_pass',
        'charset': 'utf8mb4',
        'autocommit': False
    }
    
    # WikiSQLæ•°æ®è·¯å¾„ - ä½¿ç”¨ç›¸å¯¹è·¯å¾„
    import os
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(script_dir)
    wikisql_data_path = os.path.join(project_root, "spring-ai-alibaba/spring-ai-alibaba-nl2sql/doc/pager/WikiSQL/data 2")
    
    # åˆ›å»ºå¯¼å…¥å™¨
    importer = WikiSQLQuestionsImporter(mysql_config, wikisql_data_path)
    
    try:
        # 1. è¿æ¥MySQL
        if not importer.connect_mysql():
            logger.error("âŒ æ— æ³•è¿æ¥MySQLï¼Œè¯·æ£€æŸ¥æœåŠ¡çŠ¶æ€")
            return 1
        
        # 2. å¯¼å…¥å¼€å‘é›†é—®é¢˜æ•°æ®
        logger.info("ğŸš€ å¼€å§‹å¯¼å…¥å¼€å‘é›†é—®é¢˜æ•°æ®...")
        if importer.import_questions('dev'):
            logger.info("âœ… å¼€å‘é›†é—®é¢˜æ•°æ®å¯¼å…¥æˆåŠŸ")
            
            # 3. æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            stats = importer.get_import_statistics()
            logger.info("ğŸ“Š å¯¼å…¥ç»Ÿè®¡ä¿¡æ¯:")
            for key, value in stats.items():
                logger.info(f"   {key}: {value}")
            
        else:
            logger.error("âŒ å¼€å‘é›†é—®é¢˜æ•°æ®å¯¼å…¥å¤±è´¥")
            return 1
        
        logger.info("ğŸ‰ WikiSQLé—®é¢˜æ•°æ®å¯¼å…¥å®Œæˆï¼")
        return 0
        
    except Exception as e:
        logger.error(f"âŒ å¯¼å…¥è¿‡ç¨‹å‘ç”Ÿå¼‚å¸¸: {e}")
        return 1
    finally:
        importer.close_connection()


if __name__ == "__main__":
    sys.exit(main())
