# MVP1ä¼˜åŒ–é…ç½® - é«˜æ€§èƒ½æœ¬åœ°éƒ¨ç½²
server:
  port: 8065
  servlet:
    encoding:
      charset: UTF-8
      enabled: true
      force: true
  tomcat:
    threads:
      max: 30  # å‡å°‘çº¿ç¨‹æ± ä»¥é¿å…è¿‡è½½
      min-spare: 5
    connection-timeout: 60000  # å¢åŠ è¿æ¥è¶…æ—¶åˆ°60ç§’
    max-connections: 100       # å‡å°‘æœ€å¤§è¿æ¥æ•°
    uri-encoding: UTF-8

spring:

  # ä¸»é…ç½®
  main:
    allow-bean-definition-overriding: true

  # HTTPç¼–ç é…ç½® - ä¿®å¤ä¸­æ–‡å­—ç¬¦ç¼–ç é—®é¢˜
  http:
    encoding:
      charset: UTF-8
      enabled: true   # å¯ç”¨Spring Bootå†…ç½®ç¼–ç é…ç½®
      force: true
      force-request: true
      force-response: true

  # PostgreSQLæ•°æ®åº“é…ç½® - ç³»ç»Ÿè¡¨æ•°æ®åº“ (Docker Composeéƒ¨ç½²)
  datasource:
    url: jdbc:postgresql://localhost:5432/nl2sql
    driver-class-name: org.postgresql.Driver
    username: nl2sql_user
    password: nl2sql_pass
    hikari:
      minimum-idle: 5
      maximum-pool-size: 20
      connection-timeout: 60000
      validation-timeout: 5000
      pool-name: Hikari-NL2SQL
      connection-test-query: SELECT 1

  jpa:
    hibernate:
      ddl-auto: update
    show-sql: false  # ç”Ÿäº§ç¯å¢ƒå…³é—­SQLæ—¥å¿—
    properties:
      hibernate:
        format_sql: false
        dialect: org.hibernate.dialect.PostgreSQLDialect
        jdbc:
          batch_size: 20
        order_inserts: true
        order_updates: true
    defer-datasource-initialization: true

  sql:
    init:
      mode: always
      schema-locations: classpath:sql/schema.sql
      data-locations: classpath:sql/data.sql
      continue-on-error: true
      separator: ;
      encoding: utf-8

  # proxy_openai AIæœåŠ¡é…ç½® (é€šè¿‡ proxy_openai è®¿é—® LM Studio qwen æ¨¡å‹)
  ai:
    mcp:
      server:
        name: xiyan-server-mvp1    # MCPæœåŠ¡å™¨åç§°
        version: 0.0.1           # æœåŠ¡å™¨ç‰ˆæœ¬å·
    openai:
      # base-url: http://localhost:8089
    #   # api-key: ""                      # ä½¿ç”¨åŠ¨æ€ Azure AAD tokenï¼Œä¸ä½¿ç”¨é™æ€ key
    #   model: gpt-4                     # Azure OpenAI æ¨¡å‹å
      chat:
        options:
          temperature: 0.1  # é™ä½éšæœºæ€§ï¼Œæé«˜ä¸€è‡´æ€§
          top-p: 0.9
          max-tokens: 1024  # å‡å°‘æœ€å¤§tokenæ•°ï¼Œé¿å…è¿‡é•¿è¾“å‡º
          timeout: 120000   # å¢åŠ è¶…æ—¶åˆ°120ç§’ï¼Œé€‚åº”30Bæ¨¡å‹å“åº”æ—¶é—´
          frequency-penalty: 0.5  # é¢‘ç‡æƒ©ç½šï¼Œå‡å°‘é‡å¤
          presence-penalty: 0.3   # å­˜åœ¨æƒ©ç½šï¼Œé¼“åŠ±å¤šæ ·æ€§
          stop: ["ã€‚å› æ­¤ï¼Œè¡¨ä¸­", "ä½†`BONDREGION", "ï¼Œ`BONDREGION"]  # åœæ­¢åºåˆ—ï¼Œé˜²æ­¢é‡å¤
      embedding:
        enabled: true
      openai:
        # é€šè¿‡ AiConfiguration åŠ¨æ€é€‰æ‹©ï¼šå½“ Azure AAD + Endpoint + Deployment å®Œæ•´æ—¶ï¼Œèµ° Azureï¼›å¦åˆ™èµ° base-url/api-key
        # base-url: http://localhost:8089
        # api-key: dummy-key
        # embedding:
        #   model: text-embedding-ada-002
    azure:
      tenant-id: ${AZURE_TENANT_ID:}
      client-id: ${AZURE_CLIENT_ID:}
      client-secret: ${AZURE_CLIENT_SECRET:}
      scope: https://cognitiveservices.azure.com/.default
      openai:
        endpoint: ${AZURE_OPENAI_ENDPOINT:https://your-resource.openai.azure.com}
      authority-host: https://login.microsoftonline.com
      endpoint: ${AZURE_OPENAI_ENDPOINT:https://your-resource.openai.azure.com}
      api-version: ${AZURE_OPENAI_API_VERSION:2024-02-15-preview}
      deployment-name: ${AZURE_OPENAI_DEPLOYMENT_NAME:your-deployment}
      embedding-deployment-name: ${AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME:}
      token-proxy:
        http: ${HTTP_PROXY:}
        https: ${HTTPS_PROXY:}
      enabled: true   # å¯ç”¨ Azure AAD åŠ¨æ€ token æ¨¡å¼
    dashscope:
      # api-key:                         # æœªé…ç½®åˆ™ä¸å¯ç”¨ DashScope embedding
      embedding:
        model: text-embedding-v2         # DashScope embedding æ¨¡å‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰

    # å¯ç”¨å‘é‡å­˜å‚¨
    vectorstore:
      analytic:
        enabled: false
      simple:
        enabled: true
        skip-initialization: false

    alibaba:
      nl2sql:
        container:
          enabled: false
        code-executor:
          code-pool-executor: ai_simulation  # ä½¿ç”¨AIæ¨¡æ‹Ÿæ›¿ä»£Docker
          enabled: true



  # Caffeineç¼“å­˜é…ç½®
  cache:
    type: caffeine
    caffeine:
      spec: maximumSize=1000,expireAfterWrite=30m,recordStats
    cache-names:
      - queryResults
      - schemaCache
      - vectorCache

# Qdranté…ç½®å·²ç§»é™¤ - é¡¹ç›®ä½¿ç”¨Spring AIåŸç”ŸSimpleVectorStore
# å¦‚éœ€ä½¿ç”¨Qdrantï¼Œè¯·æ·»åŠ ç›¸åº”ä¾èµ–å¹¶é…ç½®spring.ai.vectorstore.qdrant

# ä¸šåŠ¡æ•°æ®åº“é…ç½® (ä½¿ç”¨Oracle XEPDB1)
chatbi:
  dbconfig:
    url: jdbc:oracle:thin:@localhost:1521/xepdb1
    driver-class-name: oracle.jdbc.OracleDriver
    connection-type: oracle
    dialect-type: oracle
    username: nl2sql_user
    password: nl2sql_pass
    schema: NL2SQL_USER
    # æŒ‡å®šå®é™…çš„è¡¨å - Oracle XEPDB1ä¸­çš„ä¸šåŠ¡è¡¨ (å…±20ä¸ªè¡¨)
    tables: ACTV_DATA,BATCH_JOB,BATCH_JOB_INSTANCE,B_UT_ALLOC,B_UT_ASET_ALLOC,B_UT_PROD,B_UT_PROD_CAT_RISK_MEAS,B_UT_PROD_CHANL_ATTR,B_UT_PROD_OFER_CHANL,B_UT_PROD_SW,B_UT_PROD_SW_GROUP,B_UT_REFDAT_DESC,CACHE_MAP,CUSTOMER,OUTPUT_LOG,O_UT_PROD_CAT,O_UT_PROD_CAT_PERFM_RTRN,O_UT_PROD_CAT_TTL_RTRN_INDEX,PROD_CLOSE_MKT_PRICE,STG_FUNDS_CSV

# æ€§èƒ½ç›‘æ§é…ç½®
management:
  endpoints:
    web:
      exposure:
        include: health,info,metrics,prometheus
  endpoint:
    health:
      show-details: always
      show-components: always
      details:
        extended: true
    metrics:
      enabled: true
  metrics:
    export:
      prometheus:
        enabled: true
    distribution:
      percentiles-histogram:
        http.server.requests: true
      percentiles:
        http.server.requests: 0.5,0.9,0.95,0.99

# æ—¥å¿—é…ç½®
logging:
  level:
    root: TRACE
    com.alibaba.cloud.ai: TRACE
    org.springframework.ai: TRACE
    org.hibernate.SQL: TRACE
    org.hibernate.type.descriptor.sql.BasicBinder: TRACE
    org.springframework.web: TRACE
    org.springframework.boot: TRACE
    org.springframework.jdbc: TRACE
    org.springframework.transaction: TRACE
    org.apache.http: TRACE
    org.springframework.web.client: TRACE

    # ğŸ”´ å…³é—­æœ€å ç”¨ç©ºé—´çš„ä¸¤ä¸ªæ— ç”¨æ—¥å¿—
    org.apache.hc.client5.http.wire: OFF                    # Apache HTTP Client Wire æ—¥å¿— - åŒ…å«å®Œæ•´ embedding å‘é‡æ•°æ®
    org.apache.tomcat.util.net.NioEndpoint: INFO            # Tomcat NIO è½®è¯¢æ—¥å¿— - æ¯ç§’äº§ç”Ÿå¤§é‡è¶…æ—¶æ£€æŸ¥æ—¥å¿—
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n"
    file: "%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{50} - %msg%n"
  file:
    name: /Users/paulo/IdeaProjects/20250707_MCP/spring-ai-alibaba/spring-ai-alibaba-nl2sql/logs/nl2sql-mvp1.log
    max-size: 100MB
    max-history: 7
  logback:
    rollingpolicy:
      file-name-pattern: /Users/paulo/IdeaProjects/20250707_MCP/spring-ai-alibaba/spring-ai-alibaba-nl2sql/logs/nl2sql-mvp1.%d{yyyy-MM-dd}.%i.log
      max-file-size: 100MB
      max-history: 7
      total-size-cap: 1GB

# åº”ç”¨ç‰¹å®šé…ç½®
app:
  mvp1:
    # æ€§èƒ½ä¼˜åŒ–é…ç½®
    performance:
      enable-query-cache: true
      enable-schema-cache: true
      enable-vector-cache: true
      max-concurrent-queries: 5   # å‡å°‘å¹¶å‘æŸ¥è¯¢æ•°
      query-timeout: 60000        # æŸ¥è¯¢è¶…æ—¶60ç§’

    # åŠŸèƒ½å¼€å…³
    features:
      enable-complex-queries: true
      enable-chart-generation: false  # MVP1æš‚æ—¶ç¦ç”¨å›¾è¡¨ç”Ÿæˆ
      enable-export: false  # MVP1æš‚æ—¶ç¦ç”¨å¯¼å‡ºåŠŸèƒ½
      enable-batch-processing: false  # MVP1æš‚æ—¶ç¦ç”¨æ‰¹å¤„ç†

    # æ¨¡å‹é…ç½®
    models:
      chat-model: gpt-4  # é€šè¿‡ proxy_openai ä½¿ç”¨ qwen/qwen3-30b-a3b-2507
      embedding-model: text-embedding-nomic-embed-text-v1.5
      fallback-enabled: false  # MVP1ä¸ä½¿ç”¨å¤‡ç”¨æ¨¡å‹
