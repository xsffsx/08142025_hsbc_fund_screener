#!/usr/bin/env python3
"""
HSBC Fund Screener Field Extractor
æ ¹æ®å­—æ®µæ˜ å°„å…³ç³»ä»APIæ•°æ®ä¸­æå–å‰ç«¯æ˜¾ç¤ºå­—æ®µ
"""

import json
import shutil
from pathlib import Path
from typing import Dict, List, Any, Optional
from datetime import datetime

# åŸºç¡€è·¯å¾„ - ç›¸å¯¹äºè„šæœ¬ä½ç½® (åŠ¨æ€è·å–å½“å‰ç›®å½•)
SCRIPT_DIR = Path(__file__).resolve().parent
BASE_DIR = SCRIPT_DIR.parents[1]  # é¡¹ç›®æ ¹ç›®å½•
RESULT_DIR = SCRIPT_DIR / "result"
MAPPING_DIR = SCRIPT_DIR / "mapping"
MAPPING_DIR.mkdir(parents=True, exist_ok=True)

def cleanup_extracted_files():
    """æ¸…ç†ä¹‹å‰æå–çš„å­—æ®µæ–‡ä»¶"""
    print("ğŸ§¹ æ¸…ç†ä¹‹å‰æå–çš„å­—æ®µæ–‡ä»¶...")

    if MAPPING_DIR.exists():
        # åªæ¸…ç†å­—æ®µæå–ç›¸å…³çš„æ–‡ä»¶
        field_files = list(MAPPING_DIR.glob('frontend_fields_*'))
        cleaned_count = 0

        for file_path in field_files:
            if file_path.is_file():
                file_path.unlink()
                cleaned_count += 1

        print(f"âœ… å·²æ¸…ç† {cleaned_count} ä¸ªå­—æ®µæå–æ–‡ä»¶")
    else:
        print("ğŸ“ mapping ç›®å½•ä¸å­˜åœ¨ï¼Œæ— éœ€æ¸…ç†")

class FieldExtractor:
    """å­—æ®µæå–å™¨"""
    
    def __init__(self):
        self.field_mapping = self._load_field_mapping()
    
    def _load_field_mapping(self) -> Dict[str, Dict[str, Any]]:
        """åŠ è½½å­—æ®µæ˜ å°„é…ç½®"""
        # å†…ç½®å­—æ®µæ˜ å°„é…ç½®
        return {
            "Fund": {
                "api_path": "header.name",
                "data_type": "string"
            },
            "1st": {
                "api_path": "calculated:top_bond_geographic[0]",
                "data_type": "string"
            },
            "2nd": {
                "api_path": "calculated:top_bond_geographic[1]",
                "data_type": "string"
            },
            "3rd": {
                "api_path": "calculated:top_bond_geographic[2]",
                "data_type": "string"
            },
            "4th": {
                "api_path": "calculated:top_bond_geographic[3]",
                "data_type": "string"
            },
            "5th": {
                "api_path": "calculated:top_bond_geographic[4]",
                "data_type": "string"
            }
        }
    
    def _get_nested_value(self, data: Dict[str, Any], path: str) -> Any:
        """ä»åµŒå¥—å­—å…¸ä¸­è·å–å€¼"""
        # å¤„ç†top bond geographicæ’åºå­—æ®µï¼šcalculated:top_bond_geographic[index]
        if path.startswith("calculated:top_bond_geographic[") and path.endswith("]"):
            # æå–ç´¢å¼•
            import re
            match = re.search(r'top_bond_geographic\[(\d+)\]', path)
            if match:
                index = int(match.group(1))

                # è·å–bondRegionalæ•°æ®å¹¶æŒ‰æƒé‡æ’åº
                holdings_data = data.get("holdings", {})
                bond_regional_data = holdings_data.get("bondRegional", {})
                bond_regional_exposures = bond_regional_data.get("bondRegionalExposures", [])

                # åˆ›å»ºå€ºåˆ¸åœ°ç†åŒºåŸŸæƒé‡åˆ—è¡¨ï¼Œè¿‡æ»¤æ‰Otherså’Œæƒé‡ä¸º0çš„é¡¹
                regions = []
                bond_geographic_mapping = {
                    "US": "United States",
                    "LA": "Latin America",
                    "UK": "United Kingdom",
                    "EZ": "Eurozone",
                    "AE": "Asia - Emerging",
                    "CA": "Canada",
                    "AU": "Australasia",
                    "EU": "Europe",
                    "AD": "Asia - Developed",
                    "AFRICA": "Africa",
                    "JAPAN": "Japan",
                    "CHINA": "China"
                }

                for region in bond_regional_exposures:
                    region_code = region.get("name", "")
                    weight = region.get("weighting", 0)

                    # è·³è¿‡Otherså’Œæƒé‡ä¸º0çš„é¡¹
                    if region_code != "Others" and weight > 0:
                        display_name = bond_geographic_mapping.get(region_code, region_code)
                        regions.append({"name": display_name, "weight": weight})

                # æŒ‰æƒé‡é™åºæ’åº
                sorted_regions = sorted(regions, key=lambda x: x["weight"], reverse=True)

                # è¿”å›æŒ‡å®šç´¢å¼•çš„å€ºåˆ¸åœ°ç†åŒºåŸŸåç§°å’Œæƒé‡ç™¾åˆ†æ¯”
                if index < len(sorted_regions):
                    region_name = sorted_regions[index]["name"]
                    region_weight = sorted_regions[index]["weight"]
                    return f"{region_name}\n{region_weight:.2f}%"
                return ""

        # å¤„ç†è®¡ç®—å­—æ®µï¼šcalculated:100-Stock-Bond-Cash
        if path.startswith("calculated:"):
            if path == "calculated:100-Stock-Bond-Cash":
                # è·å–Stock, Bond, Cashçš„å€¼
                holdings_data = data.get("holdings", {})
                asset_alloc_data = holdings_data.get("assetAlloc", {})
                asset_allocations = asset_alloc_data.get("assetAllocations", [])

                asset_map = {}
                for allocation in asset_allocations:
                    name = allocation.get("name", "")
                    weighting = allocation.get("weighting", 0)
                    asset_map[name] = weighting

                stock_val = asset_map.get("Stock", 0)
                bond_val = asset_map.get("Bond", 0)
                cash_val = asset_map.get("Cash", 0)

                # è®¡ç®—Others = 100 - Stock - Bond - Cash
                calculated_others = 100 - stock_val - bond_val - cash_val
                return calculated_others
            return None

        # å¤„ç†ç‰¹æ®Šè·¯å¾„ï¼šheader.prodAltNumSeg[prodCdeAltClassCde=I].prodAltNum
        if "prodAltNumSeg[prodCdeAltClassCde=I]" in path:
            header_data = data.get("header", {})
            prod_alt_num_seg = header_data.get("prodAltNumSeg", [])
            for seg_item in prod_alt_num_seg:
                if seg_item.get("prodCdeAltClassCde") == "I":
                    return seg_item.get("prodAltNum")
            return None

        # å¤„ç†ç‰¹æ®Šè·¯å¾„ï¼šrisk[year=1].yearRisk.sharpeRatio
        if "risk[year=1]" in path:
            risk_data = data.get("risk", [])
            for risk_item in risk_data:
                if risk_item.get("yearRisk", {}).get("year") == 1:
                    remaining_path = path.replace("risk[year=1].", "")
                    return self._get_nested_value(risk_item, remaining_path)
            return None

        # å¤„ç†ç‰¹æ®Šè·¯å¾„ï¼šholdings.assetAlloc.assetAllocations[name=Stock].weighting
        if "assetAllocations[name=" in path:
            # æå–èµ„äº§ç±»å‹åç§°
            import re
            match = re.search(r'assetAllocations\[name=([^\]]+)\]\.weighting', path)
            if match:
                asset_name = match.group(1)
                holdings_data = data.get("holdings", {})
                asset_alloc_data = holdings_data.get("assetAlloc", {})
                asset_allocations = asset_alloc_data.get("assetAllocations", [])

                for allocation in asset_allocations:
                    if allocation.get("name") == asset_name:
                        return allocation.get("weighting")
                return None

        # æ™®é€šåµŒå¥—è·¯å¾„å¤„ç†
        keys = path.split('.')
        current = data

        for key in keys:
            if isinstance(current, dict) and key in current:
                current = current[key]
            else:
                return None

        return current
    
    def _format_value(self, value: Any, data_type: str, currency: Optional[str] = None) -> str:
        """æ ¼å¼åŒ–å€¼"""
        if value is None:
            return "N/A"
        
        if data_type == "string":
            return str(value)
        
        elif data_type == "number":
            if currency:
                return f"{value} {currency}"
            return str(value)
        
        elif data_type == "percentage":
            # å¤„ç†ç™¾åˆ†æ¯”ï¼ŒPerformanceå­—æ®µçš„APIå€¼å·²ç»æ˜¯ç™¾åˆ†æ¯”å½¢å¼ï¼Œç›´æ¥æ ¼å¼åŒ–
            if isinstance(value, (int, float)):
                return f"{value:.2f}%"
            return f"{value:.2f}%"

        elif data_type == "date":
            # å¤„ç†æ—¥æœŸæ ¼å¼ï¼Œå¦‚ "30 Dec 1994"
            if isinstance(value, str):
                try:
                    # å°è¯•è§£ææ—¥æœŸå¹¶æ ¼å¼åŒ–
                    from datetime import datetime
                    # å‡è®¾è¾“å…¥æ ¼å¼æ˜¯ "30 Dec 1994"
                    parsed_date = datetime.strptime(value, "%d %b %Y")
                    return parsed_date.strftime("%d %b %Y")
                except:
                    # å¦‚æœè§£æå¤±è´¥ï¼Œç›´æ¥è¿”å›åŸå€¼
                    return str(value)
            return str(value)

        elif data_type == "number_millions":
            millions = value / 1000000
            if currency:
                return f"{millions:.2f} (Million {currency})"
            return f"{millions:.2f} Million"

        elif data_type == "quartile_ranking":
            # å°†æ•°å­—è½¬æ¢ä¸ºå››åˆ†ä½æ’åæ ¼å¼
            if value is None:
                return "N/A"
            if value == 1:
                return "1st"
            elif value == 2:
                return "2nd"
            elif value == 3:
                return "3rd"
            elif value == 4:
                return "4th"
            else:
                return str(value)

        return str(value)
    
    def extract_product_fields(self, product_data: Dict[str, Any]) -> Dict[str, str]:
        """ä»å•ä¸ªäº§å“æ•°æ®ä¸­æå–æ‰€æœ‰å‰ç«¯å­—æ®µ"""
        extracted_fields = {}
        
        for field_name, mapping in self.field_mapping.items():
            # è·å–ä¸»è¦å€¼
            value = self._get_nested_value(product_data, mapping["api_path"])
            
            # è·å–è´§å¸å€¼ï¼ˆå¦‚æœæœ‰ï¼‰
            currency = None
            if "currency_path" in mapping:
                currency = self._get_nested_value(product_data, mapping["currency_path"])
            
            # æ ¼å¼åŒ–å€¼
            formatted_value = self._format_value(value, mapping["data_type"], currency)
            extracted_fields[field_name] = formatted_value
        
        return extracted_fields
    
    def extract_all_products(self, api_data: Dict[str, Any]) -> List[Dict[str, str]]:
        """ä»APIæ•°æ®ä¸­æå–æ‰€æœ‰äº§å“çš„å‰ç«¯å­—æ®µ"""
        products = api_data.get("responseData", {}).get("products", [])
        extracted_products = []
        
        for product in products:
            extracted_fields = self.extract_product_fields(product)
            extracted_products.append(extracted_fields)
        
        return extracted_products

def load_api_data() -> Dict[str, Any]:
    """åŠ è½½APIå“åº”æ•°æ®"""
    response_file = RESULT_DIR / "fundSearchResult_response.json"
    with open(response_file, 'r', encoding='utf-8') as f:
        return json.load(f)

def save_extracted_data(extracted_data: List[Dict[str, str]], output_file: Path):
    """ä¿å­˜æå–çš„æ•°æ®"""
    output_data = {
        "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "total_products": len(extracted_data),
        "fields": list(extracted_data[0].keys()) if extracted_data else [],
        "products": extracted_data
    }
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(output_data, f, indent=2, ensure_ascii=False)

def generate_csv_output(extracted_data: List[Dict[str, str]], csv_file: Path):
    """ç”ŸæˆCSVæ ¼å¼è¾“å‡º"""
    import csv
    
    if not extracted_data:
        return
    
    fieldnames = list(extracted_data[0].keys())
    
    with open(csv_file, 'w', newline='', encoding='utf-8') as f:
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(extracted_data)

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” å¼€å§‹æå–å‰ç«¯æ˜¾ç¤ºå­—æ®µ...")

    # æ¸…ç†ä¹‹å‰çš„å­—æ®µæå–æ–‡ä»¶
    cleanup_extracted_files()

    # åŠ è½½APIæ•°æ®
    api_data = load_api_data()
    print("âœ… APIæ•°æ®åŠ è½½å®Œæˆ")
    
    # åˆ›å»ºå­—æ®µæå–å™¨
    extractor = FieldExtractor()
    print("âœ… å­—æ®µæå–å™¨åˆå§‹åŒ–å®Œæˆ")
    
    # æå–æ‰€æœ‰äº§å“çš„å‰ç«¯å­—æ®µ
    extracted_data = extractor.extract_all_products(api_data)
    print(f"âœ… å·²æå– {len(extracted_data)} ä¸ªäº§å“çš„å­—æ®µæ•°æ®")
    
    # ä¿å­˜æå–çš„æ•°æ®
    # ä¼˜å…ˆä½¿ç”¨ç¯å¢ƒå˜é‡ä¸­çš„æ—¶é—´æˆ³ï¼ˆæ¥è‡ª05è„šæœ¬ï¼‰ï¼Œå¦åˆ™ä½¿ç”¨å½“å‰æ—¶é—´æˆ³
    import os
    timestamp = os.environ.get('FIELD_TIMESTAMP', datetime.now().strftime("%Y%m%d_%H%M%S"))
    
    # JSONæ ¼å¼ - ä¿å­˜åˆ° mapping ç›®å½•
    json_file = MAPPING_DIR / f"frontend_fields_{timestamp}.json"
    save_extracted_data(extracted_data, json_file)
    print(f"ğŸ“‹ JSONæ•°æ®å·²ä¿å­˜: {json_file}")

    # CSVæ ¼å¼ - ä¿å­˜åˆ° mapping ç›®å½•
    csv_file = MAPPING_DIR / f"frontend_fields_{timestamp}.csv"
    generate_csv_output(extracted_data, csv_file)
    print(f"ğŸ“Š CSVæ•°æ®å·²ä¿å­˜: {csv_file}")
    
    # æ˜¾ç¤ºå‰5ä¸ªäº§å“çš„ç¤ºä¾‹
    print("\nğŸ“‹ å‰5ä¸ªäº§å“çš„å­—æ®µç¤ºä¾‹:")
    for i, product in enumerate(extracted_data[:5], 1):
        print(f"\näº§å“ {i}:")
        for field, value in product.items():
            print(f"  {field}: {value}")
    
    print(f"\nğŸ¯ å­—æ®µæå–å®Œæˆï¼å…±å¤„ç† {len(extracted_data)} ä¸ªäº§å“")

if __name__ == "__main__":
    main()
