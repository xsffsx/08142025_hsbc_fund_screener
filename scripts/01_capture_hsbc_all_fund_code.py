import asyncio
from pathlib import Path
import re
import json
import csv
from datetime import datetime

from playwright.async_api import async_playwright, expect

# Generate timestamp for this run
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

# Output paths relative to project root of this submodule
BASE_DIR = Path(__file__).resolve().parents[1]
IMG_DIR = BASE_DIR / f"img_{timestamp}"
IMG_DIR.mkdir(parents=True, exist_ok=True)

# Filenames with timestamp
SHOT_1 = IMG_DIR / f"step1_open_page_{timestamp}.png"
SHOT_2 = IMG_DIR / f"step2_dropdown_open_{timestamp}.png"
SHOT_3 = IMG_DIR / f"step3_selected_speculative_{timestamp}.png"
SHOT_4 = IMG_DIR / f"step4_result_page_{timestamp}.png"
SHOT_5 = IMG_DIR / f"step5_show_50_{timestamp}.png"

TARGET_URL = "https://investments3.personal-banking.hsbc.com.hk/public/utb/en-gb/fundScreener"
RESULT_URL_PART = "/public/utb/en-gb/fundScreenerResult"

# æ•°æ®å­˜å‚¨
OUTPUT_DIR = BASE_DIR / f"output_{timestamp}"
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
PRODUCT_CODES_JSON = OUTPUT_DIR / "product_codes_all.json"
PRODUCT_CODES_CSV = OUTPUT_DIR / "product_codes_all.csv"

async def extract_product_codes_from_page(page):
    """ä»å½“å‰é¡µé¢æå–æ‰€æœ‰äº§å“ä»£ç """
    product_codes = []

    print("ğŸ” å¼€å§‹æå–å½“å‰é¡µé¢çš„äº§å“ä»£ç ...")

    # ç­‰å¾…è¡¨æ ¼åŠ è½½å®Œæˆ
    try:
        await page.wait_for_selector("[role='grid']", timeout=10000)
        await page.wait_for_timeout(2000)  # é¢å¤–ç­‰å¾…ç¡®ä¿æ•°æ®åŠ è½½
    except:
        print("âš ï¸  è¡¨æ ¼åŠ è½½è¶…æ—¶ï¼Œç»§ç»­å°è¯•æå–")

    # ç­–ç•¥1: æŸ¥æ‰¾æ‰€æœ‰Uå¼€å¤´çš„äº§å“ä»£ç 
    product_code_elements = page.locator("text=/U\\d{4,}/")
    count = await product_code_elements.count()
    print(f"ğŸ“Š æ‰¾åˆ° {count} ä¸ªæ½œåœ¨çš„äº§å“ä»£ç å…ƒç´ ")

    for i in range(count):
        try:
            element = product_code_elements.nth(i)
            if await element.is_visible():
                text = await element.text_content()
                # æå–Uå¼€å¤´çš„ä»£ç 
                import re as regex
                matches = regex.findall(r'U\d{4,}', text)
                for match in matches:
                    if match not in product_codes:
                        product_codes.append(match)
                        print(f"âœ… æå–åˆ°äº§å“ä»£ç : {match}")
        except Exception as e:
            print(f"âš ï¸  æå–ç¬¬{i}ä¸ªå…ƒç´ æ—¶å‡ºé”™: {e}")
            continue

    # ç­–ç•¥2: å¦‚æœç­–ç•¥1æ²¡æœ‰æ‰¾åˆ°è¶³å¤Ÿçš„ä»£ç ï¼Œå°è¯•æŸ¥æ‰¾è¡¨æ ¼è¡Œ
    if len(product_codes) < 10:  # é¢„æœŸæ¯é¡µè‡³å°‘æœ‰10ä¸ªä»£ç 
        print("ğŸ”„ ç­–ç•¥1ç»“æœä¸è¶³ï¼Œå°è¯•ç­–ç•¥2ï¼šæŸ¥æ‰¾è¡¨æ ¼è¡Œ...")

        # æŸ¥æ‰¾æ‰€æœ‰è¡¨æ ¼è¡Œ
        rows = page.locator("[role='row']")
        row_count = await rows.count()
        print(f"ğŸ“Š æ‰¾åˆ° {row_count} ä¸ªè¡¨æ ¼è¡Œ")

        for i in range(min(row_count, 60)):  # é™åˆ¶æ£€æŸ¥å‰60è¡Œ
            try:
                row = rows.nth(i)
                if await row.is_visible():
                    row_text = await row.text_content()
                    # åœ¨è¡Œæ–‡æœ¬ä¸­æŸ¥æ‰¾äº§å“ä»£ç 
                    matches = regex.findall(r'U\d{4,}', row_text)
                    for match in matches:
                        if match not in product_codes:
                            product_codes.append(match)
                            print(f"âœ… ä»è¡¨æ ¼è¡Œæå–åˆ°äº§å“ä»£ç : {match}")
            except Exception as e:
                continue

    # ç­–ç•¥3: æŸ¥æ‰¾é“¾æ¥ä¸­çš„äº§å“ä»£ç 
    if len(product_codes) < 10:
        print("ğŸ”„ ç­–ç•¥2ç»“æœä¸è¶³ï¼Œå°è¯•ç­–ç•¥3ï¼šæŸ¥æ‰¾é“¾æ¥...")

        links = page.locator("a")
        link_count = await links.count()
        print(f"ğŸ“Š æ‰¾åˆ° {link_count} ä¸ªé“¾æ¥")

        for i in range(min(link_count, 100)):  # é™åˆ¶æ£€æŸ¥å‰100ä¸ªé“¾æ¥
            try:
                link = links.nth(i)
                href = await link.get_attribute("href")
                text = await link.text_content()

                # åœ¨hrefå’Œæ–‡æœ¬ä¸­æŸ¥æ‰¾äº§å“ä»£ç 
                for content in [href, text]:
                    if content:
                        matches = regex.findall(r'U\d{4,}', content)
                        for match in matches:
                            if match not in product_codes:
                                product_codes.append(match)
                                print(f"âœ… ä»é“¾æ¥æå–åˆ°äº§å“ä»£ç : {match}")
            except Exception as e:
                continue

    print(f"ğŸ“‹ å½“å‰é¡µé¢å…±æå–åˆ° {len(product_codes)} ä¸ªäº§å“ä»£ç ")
    return product_codes

async def navigate_to_next_page(page, current_page):
    """å¯¼èˆªåˆ°ä¸‹ä¸€é¡µï¼Œè¿”å›æ˜¯å¦æˆåŠŸ"""
    print("ğŸ”„ å°è¯•å¯¼èˆªåˆ°ä¸‹ä¸€é¡µ...")

    # è®°å½•å½“å‰é¡µé¢çš„ä¸€äº›ç‰¹å¾ï¼Œç”¨äºéªŒè¯æ˜¯å¦çœŸçš„åˆ‡æ¢äº†é¡µé¢
    try:
        current_url = page.url
        # è·å–å½“å‰é¡µé¢çš„ç¬¬ä¸€ä¸ªäº§å“ä»£ç ä½œä¸ºæ ‡è¯†
        first_code_element = page.locator("text=/U\\d{4,}/").first
        current_first_code = await first_code_element.text_content() if await first_code_element.count() > 0 else None
        print(f"ğŸ“ å½“å‰é¡µé¢æ ‡è¯†: URL={current_url}, é¦–ä¸ªä»£ç ={current_first_code}")
    except:
        current_first_code = None

    # æŸ¥æ‰¾ä¸‹ä¸€é¡µæŒ‰é’®çš„å¤šç§ç­–ç•¥
    next_buttons = [
        page.locator("text=/Next/i"),
        page.locator("text=/ä¸‹ä¸€é¡µ/i"),
        page.locator("[aria-label*='Next']"),
        page.locator("[title*='Next']"),
        page.locator("button:has-text('>')"),
        page.locator("a:has-text('>')"),
        page.locator(".pagination .next"),
        page.locator(".pager .next"),
        page.locator(f"text='{current_page + 1}'"),  # ç›´æ¥ç‚¹å‡»é¡µç 
        page.locator(f"a:has-text('{current_page + 1}')"),
        page.locator(f"button:has-text('{current_page + 1}')")
    ]

    for i, next_button in enumerate(next_buttons):
        try:
            if await next_button.count() > 0:
                button = next_button.first
                if await button.is_visible() and await button.is_enabled():
                    print(f"âœ… æ‰¾åˆ°ä¸‹ä¸€é¡µæŒ‰é’® (ç­–ç•¥{i+1})")

                    # ç‚¹å‡»æŒ‰é’®
                    await button.click()

                    # ç­‰å¾…é¡µé¢å¼€å§‹åŠ è½½
                    await page.wait_for_timeout(2000)

                    # ç­‰å¾…ç½‘ç»œè¯·æ±‚å®Œæˆ
                    try:
                        await page.wait_for_load_state("networkidle", timeout=20000)
                    except:
                        print("âš ï¸  ç½‘ç»œç©ºé—²ç­‰å¾…è¶…æ—¶ï¼Œç»§ç»­éªŒè¯é¡µé¢å˜åŒ–")

                    # éªŒè¯é¡µé¢æ˜¯å¦çœŸçš„å‘ç”Ÿäº†å˜åŒ–
                    await page.wait_for_timeout(3000)  # é¢å¤–ç­‰å¾…ç¡®ä¿å†…å®¹æ›´æ–°

                    try:
                        new_first_code_element = page.locator("text=/U\\d{4,}/").first
                        new_first_code = await new_first_code_element.text_content() if await new_first_code_element.count() > 0 else None
                        new_url = page.url

                        print(f"ğŸ“ æ–°é¡µé¢æ ‡è¯†: URL={new_url}, é¦–ä¸ªä»£ç ={new_first_code}")

                        # æ£€æŸ¥é¡µé¢æ˜¯å¦çœŸçš„å˜åŒ–äº†
                        if new_first_code and new_first_code != current_first_code:
                            print("âœ… é¡µé¢å†…å®¹å·²æ›´æ–°ï¼ŒæˆåŠŸå¯¼èˆªåˆ°ä¸‹ä¸€é¡µ")
                            return True
                        elif new_url != current_url:
                            print("âœ… URLå·²å˜åŒ–ï¼ŒæˆåŠŸå¯¼èˆªåˆ°ä¸‹ä¸€é¡µ")
                            return True
                        else:
                            print("âš ï¸  é¡µé¢å†…å®¹ä¼¼ä¹æ²¡æœ‰å˜åŒ–ï¼Œå°è¯•ä¸‹ä¸€ä¸ªç­–ç•¥")
                            continue
                    except Exception as e:
                        print(f"âš ï¸  éªŒè¯é¡µé¢å˜åŒ–æ—¶å‡ºé”™: {e}")
                        # å¦‚æœéªŒè¯å¤±è´¥ï¼Œå‡è®¾æˆåŠŸï¼ˆç»™ä¸€æ¬¡æœºä¼šï¼‰
                        return True

        except Exception as e:
            print(f"âš ï¸  ç­–ç•¥{i+1}å¤±è´¥: {e}")
            continue

    print("âŒ æœªæ‰¾åˆ°å¯ç”¨çš„ä¸‹ä¸€é¡µæŒ‰é’®ï¼Œæˆ–é¡µé¢å†…å®¹æœªå‘ç”Ÿå˜åŒ–")
    return False

async def save_product_codes(product_codes, page_num=None):
    """ä¿å­˜äº§å“ä»£ç åˆ°æ–‡ä»¶"""
    # ä¿å­˜æ€»çš„JSONæ–‡ä»¶
    data = {
        "timestamp": timestamp,
        "total_count": len(product_codes),
        "current_page": page_num,
        "product_codes": product_codes
    }

    with open(PRODUCT_CODES_JSON, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=2, ensure_ascii=False)

    # ä¿å­˜æ€»çš„CSVæ–‡ä»¶
    with open(PRODUCT_CODES_CSV, 'w', newline='', encoding='utf-8') as f:
        writer = csv.writer(f)
        writer.writerow(['Product_Code', 'Index'])
        for i, code in enumerate(product_codes, 1):
            writer.writerow([code, i])

    print(f"ğŸ’¾ å·²ä¿å­˜ {len(product_codes)} ä¸ªäº§å“ä»£ç åˆ°:")
    print(f"   JSON: {PRODUCT_CODES_JSON}")
    print(f"   CSV: {PRODUCT_CODES_CSV}")

async def save_page_codes(page_codes, page_num):
    """ä¿å­˜å•é¡µäº§å“ä»£ç åˆ°ç‹¬ç«‹æ–‡ä»¶"""
    # æ ¼å¼åŒ–é¡µç ä¸ºä¸¤ä½æ•°
    page_str = f"{page_num:02d}"

    # å•é¡µJSONæ–‡ä»¶
    page_json_file = OUTPUT_DIR / f"product_code_page_{page_str}.json"

    page_data = {
        "timestamp": timestamp,
        "page_number": page_num,
        "page_count": len(page_codes),
        "product_codes": page_codes
    }

    with open(page_json_file, 'w', encoding='utf-8') as f:
        json.dump(page_data, f, indent=2, ensure_ascii=False)

    print(f"ğŸ“„ ç¬¬{page_num}é¡µæ•°æ®å·²ä¿å­˜: {page_json_file}")

async def main(headless: bool = True):
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=headless)
        context = await browser.new_context()
        page = await context.new_page()

        print("=== æ­¥éª¤ 1: æ‰“å¼€é¡µé¢ ===")
        await page.goto(TARGET_URL, wait_until="domcontentloaded", timeout=60000)

        # å°è¯•ç­‰å¾…ç½‘ç»œç©ºé—²ï¼Œå¦‚æœè¶…æ—¶åˆ™ç»§ç»­
        try:
            await page.wait_for_load_state("networkidle", timeout=45000)
        except Exception as e:
            print(f"âš ï¸  ç½‘ç»œç©ºé—²ç­‰å¾…è¶…æ—¶ï¼Œç»§ç»­æ‰§è¡Œ: {e}")
            await page.wait_for_timeout(2000)  # é¢å¤–ç­‰å¾…2ç§’

        if not await page.title():
            # No-op, but ensure a small delay for dynamic tags
            await page.wait_for_timeout(500)

        # POST ASSERT 1: ç¡®ä¿é¡µé¢æ ‡é¢˜åŒ…å«ç›¸å…³å…³é”®è¯æˆ–é£é™©åå¥½ä¸‹æ‹‰æ¡†å­˜åœ¨
        await expect(page).to_have_title(re.compile(r"Unit Trusts.*Search.*funds|Fund.*Screener|Investment", re.IGNORECASE))
        risk_dropdown = page.locator('a#dropdown-riskLevel')
        if await risk_dropdown.count() == 0:
            risk_dropdown = page.get_by_role("button", name=lambda n: n and ("risk tolerance" in n.lower() or "Selected" in n))
        await expect(risk_dropdown.first).to_be_visible()
        print("âœ… æ­¥éª¤ 1 å®Œæˆ: é¡µé¢å·²åŠ è½½ï¼Œé£é™©åå¥½ä¸‹æ‹‰æ¡†å¯è§")
        await page.screenshot(path=str(SHOT_1), full_page=True, scale="css")
        print(f"ğŸ“¸ æˆªå›¾å·²ä¿å­˜: {SHOT_1}")

        print("=== æ­¥éª¤ 2: æ‰“å¼€é£é™©åå¥½ä¸‹æ‹‰æ¡† ===")
        toggle = page.locator('a#dropdown-riskLevel')
        if await toggle.count() == 0:
            toggle = page.get_by_role("button", name=lambda n: n and ("Selected" in n or "risk tolerance" in n.lower()))
        await toggle.first.click()

        # POST ASSERT 2: ç¡®ä¿ä¸‹æ‹‰åˆ—è¡¨æ¡†å‡ºç°ä¸”åŒ…å« "Speculative - 5" é€‰é¡¹
        listbox = page.get_by_role("listbox")
        await expect(listbox).to_be_visible()
        speculative_option = page.get_by_role("option", name="Speculative - 5")
        if await speculative_option.count() == 0:
            speculative_option = page.get_by_text("Speculative - 5")
        await expect(speculative_option.first).to_be_visible()
        print("âœ… æ­¥éª¤ 2 å®Œæˆ: ä¸‹æ‹‰æ¡†å·²æ‰“å¼€ï¼ŒSpeculative - 5 é€‰é¡¹å¯è§")
        await page.screenshot(path=str(SHOT_2), full_page=True, scale="css")
        print(f"ğŸ“¸ æˆªå›¾å·²ä¿å­˜: {SHOT_2}")

        print("=== æ­¥éª¤ 3: é€‰æ‹© Speculative - 5 ===")
        option = page.get_by_role("option", name="Speculative - 5")
        if await option.count() == 0:
            option = page.get_by_role("button", name="Speculative - 5")
        await option.first.click()

        # POST ASSERT 3: ç¡®ä¿ä¸‹æ‹‰æ¡†æ˜¾ç¤ºå·²é€‰æ‹© "Speculative - 5" ä¸”ä¸‹æ‹‰æ¡†å·²å…³é—­
        dropdown_button = page.locator('a#dropdown-riskLevel')
        if await dropdown_button.count() == 0:
            dropdown_button = page.get_by_role("button", name=lambda n: n and "risk tolerance" in n.lower())
        await expect(dropdown_button.first).to_contain_text('Speculative - 5')
        # ç¡®ä¿ä¸‹æ‹‰åˆ—è¡¨å·²å…³é—­
        await expect(listbox).to_be_hidden()
        print("âœ… æ­¥éª¤ 3 å®Œæˆ: å·²é€‰æ‹© Speculative - 5ï¼Œä¸‹æ‹‰æ¡†å·²å…³é—­")
        await page.screenshot(path=str(SHOT_3), full_page=True, scale="css")
        print(f"ğŸ“¸ æˆªå›¾å·²ä¿å­˜: {SHOT_3}")

        print("=== æ­¥éª¤ 4: ç‚¹å‡»æœç´¢æŒ‰é’® ===")
        search_btn = page.get_by_test_id("Search")
        if await search_btn.count() == 0:
            search_btn = page.get_by_role("button", name="Search")
        await expect(search_btn).to_be_enabled()
        async with page.expect_response(lambda r: "fundSearchResult" in r.url and r.status == 200):
            await search_btn.click()

        # POST ASSERT 4: ç¡®ä¿è·³è½¬åˆ°ç»“æœé¡µé¢ä¸”æ˜¾ç¤ºæœç´¢ç»“æœç›¸å…³å…ƒç´ 
        await expect(page).to_have_url(re.compile(re.escape(RESULT_URL_PART)))
        await page.wait_for_load_state("networkidle")

        # ç¡®ä¿ç»“æœé¡µé¢çš„å…³é”®å…ƒç´ å­˜åœ¨ï¼šShow æ§ä»¶å’ŒåŸºé‡‘åˆ—è¡¨ç½‘æ ¼
        show_controls = page.get_by_text("Show:")
        await expect(show_controls.first).to_be_visible()
        grid = page.get_by_role("grid")
        await expect(grid).to_be_visible()

        # å®šä½å¹¶éªŒè¯ "Results" å’Œ "1407 matches" æ–‡æœ¬
        print("ğŸ” å®šä½æœç´¢ç»“æœç»Ÿè®¡ä¿¡æ¯...")

        # æ–¹æ³•1: ç›´æ¥æŸ¥æ‰¾åŒ…å« "Results" å’Œæ•°å­—çš„æ–‡æœ¬
        results_text = page.locator("text=/Results/i")
        matches_text = page.locator("text=/\\d+\\s+matches/i")

        # æ–¹æ³•2: å¤‡ç”¨é€‰æ‹©å™¨ - æŸ¥æ‰¾åŒ…å« "matches" çš„ä»»ä½•æ–‡æœ¬
        if await results_text.count() == 0:
            results_text = page.locator("text=/result/i")

        if await matches_text.count() == 0:
            matches_text = page.locator("text=/\\d+.*match/i")

        # æ–¹æ³•3: ä½¿ç”¨æ›´å®½æ³›çš„é€‰æ‹©å™¨æŸ¥æ‰¾æ•°å­—+matchesæ¨¡å¼
        if await matches_text.count() == 0:
            matches_text = page.locator("text=/\\d{3,}.*match/i")  # è‡³å°‘3ä½æ•°å­—

        # éªŒè¯Resultsæ–‡æœ¬å­˜åœ¨
        if await results_text.count() > 0:
            await expect(results_text.first).to_be_visible()
            results_content = await results_text.first.text_content()
            print(f"âœ… æ‰¾åˆ°Resultsæ–‡æœ¬: '{results_content}'")
        else:
            print("âš ï¸  æœªæ‰¾åˆ°Resultsæ–‡æœ¬ï¼Œç»§ç»­æŸ¥æ‰¾matchesä¿¡æ¯")

        # éªŒè¯matchesæ–‡æœ¬å­˜åœ¨å¹¶æå–æ•°å­—
        if await matches_text.count() > 0:
            await expect(matches_text.first).to_be_visible()
            matches_content = await matches_text.first.text_content()
            print(f"âœ… æ‰¾åˆ°matchesæ–‡æœ¬: '{matches_content}'")

            # æå–æ•°å­—
            import re as regex
            match_numbers = regex.findall(r'\d+', matches_content)
            if match_numbers:
                total_matches = match_numbers[0]
                print(f"ğŸ“Š æœç´¢ç»“æœæ€»æ•°: {total_matches} matches")

                # æ–­è¨€ï¼šéªŒè¯ç»“æœæ•°é‡å¤§äº0
                assert int(total_matches) > 0, f"æœç´¢ç»“æœæ•°é‡åº”å¤§äº0ï¼Œå®é™…ä¸º: {total_matches}"
                print(f"âœ… æ–­è¨€é€šè¿‡: æœç´¢ç»“æœæ•°é‡ {total_matches} > 0")
            else:
                print("âš ï¸  æ— æ³•ä»matchesæ–‡æœ¬ä¸­æå–æ•°å­—")
        else:
            print("âš ï¸  æœªæ‰¾åˆ°matchesæ–‡æœ¬ï¼Œå°è¯•å…¶ä»–æ–¹æ³•...")

            # æ–¹æ³•4: ä½¿ç”¨MCPé£æ ¼çš„æ›´ç²¾ç¡®å®šä½
            # æŸ¥æ‰¾åŒ…å«æ•°å­—çš„ä»»ä½•å…ƒç´ 
            all_text_elements = page.locator("text=/\\d{3,}/")
            if await all_text_elements.count() > 0:
                for i in range(min(5, await all_text_elements.count())):  # æ£€æŸ¥å‰5ä¸ªåŒ¹é…
                    element = all_text_elements.nth(i)
                    if await element.is_visible():
                        content = await element.text_content()
                        if 'match' in content.lower() or 'result' in content.lower():
                            print(f"âœ… é€šè¿‡å¤‡ç”¨æ–¹æ³•æ‰¾åˆ°ç»“æœæ–‡æœ¬: '{content}'")
                            break

        print("âœ… æ­¥éª¤ 4 å®Œæˆ: å·²è·³è½¬åˆ°ç»“æœé¡µé¢ï¼ŒShow æ§ä»¶å’ŒåŸºé‡‘ç½‘æ ¼å¯è§ï¼Œæœç´¢ç»“æœç»Ÿè®¡å·²éªŒè¯")
        await page.screenshot(path=str(SHOT_4), full_page=True, scale="css")
        print(f"ğŸ“¸ æˆªå›¾å·²ä¿å­˜: {SHOT_4}")

        print("=== æ­¥éª¤ 5: é€‰æ‹©æ˜¾ç¤º 50 æ¡è®°å½• ===")
        # The control is a list of buttons; choose the one named "50"
        show_50 = page.get_by_role("button", name="50")
        await expect(show_50).to_be_visible()
        await show_50.click()

        # POST ASSERT 5: ç¡®ä¿é¡µé¢æ˜¾ç¤º50æ¡è®°å½•ä¸”åŠ è½½å®Œæˆ
        # ç­‰å¾…ç½‘æ ¼å¯è§
        grid = page.get_by_role("grid")
        await expect(grid).to_be_visible()

        # ç­‰å¾…åŠ è½½æŒ‡ç¤ºå™¨æ¶ˆå¤±
        try:
            await page.wait_for_selector("[data-testid='loading'], .loading, [role='progressbar']", state="hidden", timeout=5000)
        except:
            pass

        # ç­‰å¾…è‡³å°‘ä¸€äº›åŸºé‡‘è¡Œå‡ºç°ï¼ˆåŸºé‡‘ä»£ç å¦‚ "U123" æ¨¡å¼ï¼‰
        try:
            await page.wait_for_selector("text=/U\\d{3}/", timeout=10000)
        except:
            pass

        # æœ€ç»ˆç­‰å¾…ä»»ä½•å‰©ä½™çš„å¼‚æ­¥æ›´æ–°
        await page.wait_for_timeout(1000)

        # éªŒè¯é¡µé¢æ˜¾ç¤ºçš„è®°å½•æ•°é‡ç›¸å…³ä¿¡æ¯
        # å¯»æ‰¾æ˜¾ç¤ºè®°å½•æ•°çš„æ–‡æœ¬ï¼Œå¦‚ "Showing 1-50 of XXX" æˆ–ç±»ä¼¼æ ¼å¼
        try:
            showing_text = page.locator("text=/showing.*50|1.*50.*of|displaying.*50/i")
            if await showing_text.count() > 0:
                await expect(showing_text.first).to_be_visible()
                print("âœ… æ­¥éª¤ 5 å®Œæˆ: é¡µé¢æ˜¾ç¤º50æ¡è®°å½•ï¼Œæ•°æ®åŠ è½½å®Œæˆ")
            else:
                # å¤‡ç”¨éªŒè¯ï¼šæ£€æŸ¥ç½‘æ ¼ä¸­æ˜¯å¦æœ‰è¶³å¤Ÿçš„è¡Œ
                rows = page.locator("[role='row']")
                row_count = await rows.count()
                print(f"âœ… æ­¥éª¤ 5 å®Œæˆ: ç½‘æ ¼æ˜¾ç¤º {row_count} è¡Œæ•°æ®")
        except:
            print("âœ… æ­¥éª¤ 5 å®Œæˆ: Show 50 å·²ç‚¹å‡»ï¼Œé¡µé¢æ•°æ®å·²åŠ è½½")

        await page.screenshot(path=str(SHOT_5), full_page=True, scale="css")
        print(f"ğŸ“¸ æˆªå›¾å·²ä¿å­˜: {SHOT_5}")

        print("\n" + "="*60)
        print("ğŸš€ å¼€å§‹æå–æ‰€æœ‰äº§å“ä»£ç  (ç›®æ ‡: 1407ä¸ª)")
        print("="*60)

        all_product_codes = []
        page_num = 1
        max_pages = 30  # å®Œæ•´æ¨¡å¼ï¼šè·å–æ‰€æœ‰1407ä¸ªäº§å“ä»£ç 

        while page_num <= max_pages:
            print(f"\nğŸ“„ å¤„ç†ç¬¬ {page_num} é¡µ...")

            # æå–å½“å‰é¡µé¢çš„äº§å“ä»£ç 
            page_codes = await extract_product_codes_from_page(page)

            if not page_codes:
                print("âš ï¸  å½“å‰é¡µé¢æœªæå–åˆ°äº§å“ä»£ç ï¼Œå¯èƒ½å·²åˆ°æœ€åä¸€é¡µ")
                break

            # æ·»åŠ åˆ°æ€»åˆ—è¡¨ï¼ˆå»é‡ï¼‰
            new_codes = []
            for code in page_codes:
                if code not in all_product_codes:
                    all_product_codes.append(code)
                    new_codes.append(code)

            print(f"âœ… ç¬¬{page_num}é¡µæ–°å¢ {len(new_codes)} ä¸ªäº§å“ä»£ç ")
            print(f"ğŸ“Š ç´¯è®¡æ”¶é›† {len(all_product_codes)} ä¸ªäº§å“ä»£ç ")

            # æ–­è¨€éªŒè¯ï¼šæ£€æŸ¥ç¬¬ä¸€ä¸ªå’Œæœ€åä¸€ä¸ªäº§å“ä»£ç 
            if page_codes:
                first_code = page_codes[0]
                last_code = page_codes[-1]

                print(f"ğŸ” éªŒè¯ç¬¬{page_num}é¡µäº§å“ä»£ç èŒƒå›´:")
                print(f"   é¦–ä¸ªä»£ç : {first_code}")
                print(f"   æœ«ä¸ªä»£ç : {last_code}")

                # æ–­è¨€ï¼šç¡®ä¿äº§å“ä»£ç æ ¼å¼æ­£ç¡®
                import re as regex
                assert regex.match(r'^U\d{4,}$', first_code), f"ç¬¬{page_num}é¡µé¦–ä¸ªä»£ç æ ¼å¼é”™è¯¯: {first_code}"
                assert regex.match(r'^U\d{4,}$', last_code), f"ç¬¬{page_num}é¡µæœ«ä¸ªä»£ç æ ¼å¼é”™è¯¯: {last_code}"

                # æ–­è¨€ï¼šç¡®ä¿é¡µé¢æœ‰è¶³å¤Ÿçš„äº§å“ä»£ç 
                expected_count = 50 if page_num < 29 else min(50, 1407 - (page_num - 1) * 50)
                assert len(page_codes) >= min(expected_count, 10), f"ç¬¬{page_num}é¡µäº§å“ä»£ç æ•°é‡ä¸è¶³: {len(page_codes)} < {min(expected_count, 10)}"

                print(f"âœ… ç¬¬{page_num}é¡µæ–­è¨€éªŒè¯é€šè¿‡:")
                print(f"   âœ“ é¦–ä¸ªä»£ç æ ¼å¼: {first_code}")
                print(f"   âœ“ æœ«ä¸ªä»£ç æ ¼å¼: {last_code}")
                print(f"   âœ“ ä»£ç æ•°é‡: {len(page_codes)} ä¸ª")
            else:
                print(f"âŒ ç¬¬{page_num}é¡µæœªæå–åˆ°ä»»ä½•äº§å“ä»£ç ")
                assert False, f"ç¬¬{page_num}é¡µäº§å“ä»£ç æå–å¤±è´¥"

            # ä¿å­˜å½“å‰é¡µçš„äº§å“ä»£ç åˆ°ç‹¬ç«‹æ–‡ä»¶
            await save_page_codes(page_codes, page_num)

            # æ¯é¡µéƒ½ä¿å­˜ä¸€æ¬¡æ€»æ–‡ä»¶ï¼ˆé˜²æ­¢æ•°æ®ä¸¢å¤±ï¼‰
            await save_product_codes(all_product_codes, page_num)

            # æ‹æ‘„å½“å‰é¡µé¢æˆªå›¾
            page_screenshot = IMG_DIR / f"page_{page_num}_codes_{timestamp}.png"
            await page.screenshot(path=str(page_screenshot), full_page=True, scale="css")
            print(f"ğŸ“¸ é¡µé¢æˆªå›¾å·²ä¿å­˜: {page_screenshot}")

            # æ£€æŸ¥æ˜¯å¦å·²æ”¶é›†åˆ°ç›®æ ‡æ•°é‡
            if len(all_product_codes) >= 1407:
                print(f"ğŸ¯ å·²è¾¾åˆ°ç›®æ ‡æ•°é‡ï¼æ”¶é›†åˆ° {len(all_product_codes)} ä¸ªäº§å“ä»£ç ")
                break

            # å°è¯•å¯¼èˆªåˆ°ä¸‹ä¸€é¡µ
            if not await navigate_to_next_page(page, page_num):
                print("ğŸ“„ å·²åˆ°æœ€åä¸€é¡µï¼Œåœæ­¢éå†")
                break

            page_num += 1

            # é¢å¤–ç­‰å¾…ç¡®ä¿é¡µé¢å®Œå…¨åŠ è½½
            await page.wait_for_timeout(2000)

        print("\n" + "="*60)
        print("ğŸ“Š æ•°æ®æ”¶é›†å®Œæˆç»Ÿè®¡")
        print("="*60)
        print(f"ğŸ¯ ç›®æ ‡æ•°é‡: 1407")
        print(f"âœ… å®é™…æ”¶é›†: {len(all_product_codes)}")
        print(f"ğŸ“„ éå†é¡µæ•°: {page_num}")
        print(f"ğŸ“ æ•°æ®æ–‡ä»¶: {PRODUCT_CODES_JSON}")
        print(f"ğŸ“ CSVæ–‡ä»¶: {PRODUCT_CODES_CSV}")

        # æœ€ç»ˆä¿å­˜
        await save_product_codes(all_product_codes, page_num)

        # æ˜¾ç¤ºå‰10ä¸ªå’Œå10ä¸ªäº§å“ä»£ç ä½œä¸ºéªŒè¯
        if all_product_codes:
            print(f"\nğŸ“‹ äº§å“ä»£ç æ ·æœ¬:")
            print(f"å‰10ä¸ª: {all_product_codes[:10]}")
            if len(all_product_codes) > 10:
                print(f"å10ä¸ª: {all_product_codes[-10:]}")

        print(f"\nğŸ¯ æ‰€æœ‰æˆªå›¾å·²ä¿å­˜åˆ°ç›®å½•: {IMG_DIR}")
        print("ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
        for shot_file in [SHOT_1, SHOT_2, SHOT_3, SHOT_4, SHOT_5]:
            if shot_file.exists():
                size_kb = shot_file.stat().st_size // 1024
                print(f"  - {shot_file.name} ({size_kb}KB)")

        # æ˜¾ç¤ºé¡µé¢æˆªå›¾
        page_screenshots = list(IMG_DIR.glob(f"page_*_codes_{timestamp}.png"))
        if page_screenshots:
            print(f"ğŸ“„ é¡µé¢æˆªå›¾ ({len(page_screenshots)}ä¸ª):")
            for shot in page_screenshots:
                size_kb = shot.stat().st_size // 1024
                print(f"  - {shot.name} ({size_kb}KB)")

        await context.close()
        await browser.close()

if __name__ == "__main__":
    # Default headless to True for CI stability
    asyncio.run(main(headless=True))

